# Mod 3 Exposer une base de donnÃ©es relationnelle via une API REST et entrainement d'un modÃ¨le
###### Le `.venv` 


```bash
python -m venv .venv
```


* **Windows (PowerShell) :**
    ```bash
    .\.venv\Scripts\Activate.ps1
    ```
* **Windows (CMD) :**
    ```bash
    .\.venv\Scripts\activate.bat
    ```
* **macOS / Linux :**
    ```bash
    source .venv/bin/activate
    ```


###### Le `requirements.txt`


Assure-toi que ton `.venv` est activÃ©, puis :

```bash
pip install -r requirements.txt
```


#### ğŸ—ºï¸ Architecture : OÃ¹ va quoi dans notre petit monde ? ğŸ—ºï¸


.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data-all-684bf775c031b265646213.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ model_2024_08.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ alchemy-api.log
â”‚   â””â”€â”€ main_api.log
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ print_draw.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ main_api.py => API FastAPI 
â”œâ”€â”€ alchemy_api.py => Niveau 0 API
â””â”€â”€ requirements.txt
```

###### `data/`
* `data-all-684bf775c031b265646213.csv` : Les donnÃ©es de base Ã  traiter.

###### `figures/` (L'analyste visuelle)
Sauvegarde des images des courbes de coÃ»t et autres graphiques pour visualiser les performances de notre modÃ¨le.

###### `models/` (Le garage Ã  cerveaux)
Ce dossier, c'est notre caverne d'Ali Baba des cerveaux artificiels.
* `models.py` : Les plans de nos futurs cyborgs... euh, de nos modÃ¨les. C'est ici que l'on dÃ©finit l'architecture de nos NN et autres merveilles.
* `model_2024_08.pkl` : Une version sauvegardÃ©e de notre modÃ¨le. On l'a encapsulÃ© pour qu'il ne s'Ã©chappe pas et ne domine pas le monde... pas encore.
* `preprocessor.pkl` : L'outil magique qui prÃ©pare les donnÃ©es avant de les donner Ã  manger au modÃ¨le. Sans lui, c'est l'indigestion assurÃ©e !

###### `modules/` (La boÃ®te Ã  outils de MacGyver)
Ce sont nos couteaux suisses du code. Chaque fichier est un expert dans son domaine.
* `evaluate.py` : Le juge impitoyable qui dit si notre modÃ¨le est un gÃ©nie ou un cancre.
* `preprocess.py` : Le chef cuisinier des donnÃ©es. Il les nettoie, les coupe, les assaisonne pour qu'elles soient parfaites pour notre IA.
* `print_draw.py` : L'artiste du groupe. Il transforme nos chiffres barbares en beaux graphiques pour que mÃªme ta grand-mÃ¨re puisse comprendre (enfin, presque).

---

On espÃ¨re que cette petite virÃ©e dans notre projet t'a plu. N'hÃ©site pas Ã  jeter un Å“il au `main.py` pour lancer le grand spectacle !

*Fait avec amour, code et une bonne dose de cafÃ©ine (et un peu de folie).*


# TD => GOGOGO
## setup

- ### GÃ©nÃ©ration requirements.txt Ã  chaque installation de module
```bash
pip freeze > requirements.txt
```

- ### Installations des requis sqlAlchemy: 
```bash
pip install psycopg2-binary
pip install pydantic-sqlalchemy
```
- ### Installations des requis Mod3 Brief 2: 
```bash
pip install tensorflow
```

- ### Installations des requis loguru: 
```bash
pip install loguru
```

- ### Installations des requis FastAPI/Streamlit: 
```bash
pip install nltk fastapi streamlit uvicorn requests pydantic
```
- #### Pour lancer le serveur MLflow :
```bash
uvicorn main_api:app --host 127.0.0.1 --port 8000 --reload
```
- #### Description des routes de l'API FastAPI :
[GET /docs](http://127.0.0.1:8000/docs#/)


- ### Installation des bibliothÃ¨ques pour les tests unitaires: 
```bash
pip install pytest httpx
pytest test_predict_api.py
```

- ### Installations des requis pour MLflow : 
  > **mlFlow**
  MlFlow est un outil de gestion des expÃ©riences de machine learning. Il permet de suivre les expÃ©riences, de gÃ©rer les modÃ¨les et de visualiser les rÃ©sultats.
```bash
pip install mlflow scikit-learn pandas matplotlib
```

# Pour lancer le serveur MLflow :
```bash
mlflow ui
```

## Streamlit
lancer le serveur Streamlit pour l'interface utilisateur :
```bash
streamlit run streamlit_app.py
```
### Pour accÃ©der au front (root + pages entrainnement et prediction :)
[Streamlit Front](http://localhost:8501)


## DÃ©roulÃ© du travail
CrÃ©ation d'un script pour gÃ©nÃ©rer 3 entrainements et les stocker sur MLflow : 
Les models crÃ©Ã© sont stockÃ©s dans le dossier `models/` et pictures du drawloss sont stockÃ©s dans le dossier `figures/`.


- J'ai mis en place :
  - Un script pour lancer 5 entrainements sur les anciennes donnÃ©es et 5 sur les nouvelles donnÃ©es.
  - le suivi des performances de chaque entrainement dans MLflow. (possibilitÃ© de stocker ou pas les modÃ¨les et les graph de loss)
  - les tests unitaires avec pytest
  - le loging des performances avec `loguru` et un setup simplifiÃ© pour le logger.
  - les images des couts stockÃ©s dans le dossier `figures/`.
  - Une route `/predict` pour faire des prÃ©dictions sur des donnÃ©es envoyÃ©es via questionnaire *Streamlit*.
  - Une route `/retrain` pour rÃ©entrainer le modÃ¨le (in progress).
  - Containerisation avec docker File puis docker-compose 
  - Stockage de l'id du model en local dans un fichier pour le retrouver depuis docker



**Docker : Build & Run**

Pour builder lâ€™image Docker manuellementâ€¯:
```bash
docker build -t mlflow-app .
```
Puis lancer le conteneur (tous services dans le mÃªme conteneur)â€¯:
```bash
docker run -p 8000:8000 -p 8501:8501 -p 5000:5000 mlflow-app
```

- FastAPI : http://localhost:8000/docs
- Streamlit : http://localhost:8501
- MLflow UI : http://localhost:5000

**Avec Docker Compose (meilleur approche)**

Pour builder et lancer tous les services (API, Streamlit, MLflow) dans des conteneurs sÃ©parÃ©sâ€¯:
```bash
docker compose up --build
```

Pour tout arrÃªter proprementâ€¯:
```bash
docker compose down
```


```powershell
wsl --unregister docker-desktop
wsl --unregister docker-desktop-data
```

## setup docker postgresql
```powershell
docker compose -f docker-compose-postgres.yml up -d
```

## Etape clÃ©s du projet
- J'ai crÃ©Ã© un nouveau projet Ã  partir des modules prÃ©cÃ©dent : FastAPI / MLFlow / Streamlit/ LOGURU / Docker / 
- Le jeu de donnÃ©es est stockÃ© dans le dossier `data/` sous le nom `data-all-684bf775c031b265646213.csv`.
- J'ai suivi le module sur la prise en main de SQL Alchimy et la gestion ORM
- Le notebook est disponible dans le dossier `notebooks/` sous le nom `SQLAlchemy_exploration.ipynb`.
- Utilisation du notebook crÃ©Ã© lors du module 2 pour analyser et crÃ©er un jeu de donnÃ©es propre (CSV).
- RÃ©utilisation du notebook crÃ©Ã© lors du module 2 pour analyser le jeu de donnÃ©es, comprendre les donnÃ©es et les nettoyer.
- Le notebook est disponible dans le dossier `notebooks/` sous le nom `ethique_data_cleaning.ipynb`.
- J'ai crÃ©Ã© un script `python alchemy_api.py clean_dataset` pour nettoyer le jeu de donnÃ©es et le stocker dans le dossier `data/`.
- J'ai crÃ©Ã© une DB PostgreSQL containerisÃ© que j'ai rempli avec les valeurs  j'ai crÃ©Ã© un CRUD sur la ressource Client. J'ai Ã©galement crÃ©Ã© un prÃ©processeur et j'ai crÃ©Ã© un modÃ¨le que j'ai entraÃ®nÃ© avec les donnÃ©es prÃ©processÃ©es de la DB.
- J'ai changÃ© le preprocesseur pour s'adapter aux nouvelles colonnes du jeu de donnÃ©es.
- J'ai crÃ©Ã© des scripts utilitaires pour injecter les donnÃ©es `python inject_data.py init`
- Ajout du module pydantic-sqlalchemy pour gÃ©rer les changements de modÃ¨les et rendre + dynamique pydantic

## Quelles difficultÃ©s jâ€™ai rencontrÃ©es ? 
- l'apprentissage des nouvelles librairies et leur implÃ©mentation dans une architecture relativement propre, la rÃ©utilisation d"outils dÃ©ja vu (MLFlow ...). 
- Je suis repassÃ© sur sqllite en db car trop de soucis avec postgres
- 
## Quâ€™est-ce que jâ€™ai appris ? 
- J'ai appris Ã  utiliser l'ORM SQLAlchemy et Ã  gÃ©rer une DB avec.
- J'ai consolidÃ© les outils Ã  ma disposition pour crÃ©er une API REST et un modÃ¨le de machine learning : 
  - Simplification de l'initialisation 
  ```python 
    ## Base initialisation for Loguru and FastAPI
    from myapp_base import setup_loguru, app, Request, HTTPException
    logger = setup_loguru("logs/alchemy_api.log")
  ```





> **Note :** A quoi sert le modÃ¨le ?

### Flux de donnÃ©es et transformations

- Les donnÃ©es brutes sont importÃ©es depuis un fichier CSV (`data-all-complete-684bf9cd92797851623245.csv`).
- Un nettoyage Ã©thique est rÃ©alisÃ© dans le notebook `ethique_data_cleaning_complete.ipynb`Â :  
  - Suppression des colonnes sensibles ou non conformes (nom, prÃ©nom, sexe, nationalitÃ©, orientation sexuelle, date de crÃ©ation de compte).
  - Remplissage des valeurs manquantes pour certaines colonnes (`loyer_mensuel` par la moyenne, `situation_familiale` par la modalitÃ© la plus frÃ©quente).
  - Filtrage des valeurs aberrantes (poids, nb_enfants, quotient_caf, loyer_mensuel).
  - Suppression des colonnes avec trop de valeurs manquantes (`score_credit`, `historique_credits`).
- Le dataset nettoyÃ© est sauvegardÃ© sous `df_data_all_complete_cleaned.csv` puis injectÃ© dans la base via le script `inject_data.py`.

### SchÃ©ma de la base de donnÃ©es

- Table principaleÂ : `loandatas`
- ColonnesÂ :  
  `id`, `age`, `taille`, `poids`, `nb_enfants`, `quotient_caf`, `sport_licence`, `niveau_etude`, `region`, `smoker`, `revenu_estime_mois`, `situation_familiale`, `risque_personnel`, `loyer_mensuel`, `montant_pret`
- Le schÃ©ma est versionnÃ© et documentÃ© via les migrations Alembic.

### Ã‰valuation Ã©thique

- Les colonnes Ã  risque de discrimination ou dâ€™identification ont Ã©tÃ© supprimÃ©es.
- Les choix de remplissage et de filtrage sont documentÃ©s dans le notebook.
- Les risques de biais restants sont identifiÃ©s 

---


# Brief 2 :
Objectif : Adapter un modÃ¨le IA existant (TensorFlow/Keras) Ã  de nouvelles colonnes dâ€™entrÃ©e, sans perdre les poids internes, puis le rÃ©entraÃ®ner sur un dataset enrichi.
Suivi des performancesâ€¯: MLflow ou TensorBoard.
Exposition du modÃ¨leâ€¯: API FastAPI prenant en compte les nouvelles colonnes.
Livrables attendusâ€¯:
Nouveau modÃ¨le entraÃ®nÃ© (.h5, .pkl ou SavedModel)
Script de modification de lâ€™architecture + script dâ€™entraÃ®nement
Script/projet FastAPI pour lâ€™API
Journal de suivi MLflow
README dÃ©taillÃ©


- j'ai refacto le code pour rendre dynamique les usages de colonnes pour l'entrainnement du model
- J'ai ajoutÃ© la stratÃ©gie de missing pour les colonnes incompletes (Remplissage + indication dans une colonne dÃ©diÃ© pour savoir si la valeur etait manquante ou pas Ã  la base)
- entraÃ®nement du model : python alchemy_api.py train
  
## Performance 1er entrainnement :
==================Performance for run 0/1===================
MSE: 77444596.8351, MAE: 6463.7837, RÂ²: 0.3169
============================================================


- test avec notebook
- Codage Codage Codage...
- Ajout stratÃ©gie de transfert de poids en option de settings


## ExÃ©cution du script d'entraÃ®nement en transferant les poids du premier model
60/60 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step 
==================Performance for run 0/1===================
MSE: 61944948.3360, MAE: 5717.0758, RÂ²: 0.4537
============================================================
Model enregistrÃ© dans models/model_20250620_1536_0_None.pkl
Courbe de loss : model_20250620_1536_0_None.jpg



- CrÃ©ation d'un script pour enregistrer le preprocess pour la route de prÃ©diction
- Changement de type pour la donnÃ©es 

- Utilisation d'une data d'enregirstrement de l'ordre des colonne pour completer la route de prÃ©diction.